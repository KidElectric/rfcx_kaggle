{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import librosa as lb\n",
    "import librosa.display\n",
    "import soundfile as sf\n",
    "import matplotlib.patches as patch\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.io import wavfile\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "from skimage import io\n",
    "from skimage.color import rgb2gray,rgba2rgb\n",
    "#https://github.com/iver56/audiomentations ?\n",
    "%matplotlib inline\n",
    "CC_ROOT=Path(\"D:\\\\KidElectric\\\\rfcx_kaggle\") #Cookiecutter datascience-style project\n",
    "CC_DATA_OUT=CC_ROOT.joinpath('data').joinpath('interim')\n",
    "\n",
    "DATA_ROOT = CC_ROOT.joinpath('data')\n",
    "TRAIN_AUDIO_ROOT = DATA_ROOT.joinpath('raw').joinpath('train')#Update to point to cookiecutter data/raw/train\n",
    "TEST_AUDIO_ROOT = DATA_ROOT.joinpath('raw').joinpath('test')#Update to point to cookiecutter data/raw/test\n",
    "\n",
    "\n",
    "df_train = pd.DataFrame({\n",
    "    \"recording_id\": [path.stem for path in TRAIN_AUDIO_ROOT.glob(\"*.flac\")],\n",
    "})\n",
    "\n",
    "df_test = pd.DataFrame({\n",
    "    \"recording_id\": [path.stem for path in TEST_AUDIO_ROOT.glob(\"*.flac\")],\n",
    "})\n",
    "\n",
    "df_tp=pd.read_csv(CC_ROOT.joinpath('references').joinpath('train_tp.csv')).set_index('recording_id')\n",
    "\n",
    "df_fp=pd.read_csv(CC_ROOT.joinpath('references').joinpath('train_fp.csv')).set_index('recording_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class params:\n",
    "    \"\"\"\n",
    "    Parameters used for generating spectrograms from audio data\n",
    "    \"\"\"\n",
    "    sr = 48000 #sampling rate\n",
    "\n",
    "    # Melspectrogram\n",
    "    n_mels = 128\n",
    "    fmin = 80\n",
    "    fmax = 14000  \n",
    "    n_fft=2048\n",
    "    hop_length = 512\n",
    "\n",
    "def load_audio(pnfn=\"\", sr=48000):\n",
    "    y, _ = lb.load(pnfn,\n",
    "        sr=sr, \n",
    "    )\n",
    "    return y\n",
    "\n",
    "def compute_melspec(y, params):\n",
    "    \"\"\"\n",
    "    Computes a mel-spectrogram and puts it at decibel scale\n",
    "    Arguments:\n",
    "        y {np array} -- signal\n",
    "        params {AudioParams} -- Parameters to use for the spectrogram. Expected to have the attributes sr, n_mels, f_min, f_max\n",
    "    Returns:\n",
    "        np array -- Mel-spectrogram\n",
    "    \"\"\"\n",
    "    melspec = lb.feature.melspectrogram(\n",
    "        y, sr=params.sr, n_mels=params.n_mels,\n",
    "        fmin=params.fmin, fmax=params.fmax, center=True, pad_mode='reflect',\n",
    "        hop_length=params.hop_length,n_fft=params.n_fft\n",
    "    )\n",
    "    melspec = lb.power_to_db(melspec).astype(np.float32)\n",
    "    return melspec\n",
    "\n",
    "def has_tp_fp(rec,df_tp,df_fp):\n",
    "    #Many recordings have both tp and fp data labeled.\n",
    "    has_tp=False\n",
    "    has_fp=False\n",
    "    if rec in df_tp.index:\n",
    "        has_tp = True\n",
    "    if rec in df_fp.index:\n",
    "        has_fp = True\n",
    "    return has_tp, has_fp\n",
    "\n",
    "def clip_info(rec,df):\n",
    "    keep={'species_id':[],'t_min':[],'t_max':[]}\n",
    "    for key in df.keys():\n",
    "        if key in keep.keys():\n",
    "            if isinstance(df[key][rec],pd.core.series.Series):\n",
    "                keep[key]=[val for val in df[key][rec].values]\n",
    "            else:\n",
    "                keep[key].append(df[key][rec])\n",
    "    return keep\n",
    "\n",
    "def clip_identity(rec,df_tp,df_fp,start,stop):\n",
    "    out={'tp_spec':[],'tp':0,\n",
    "         'fp_spec':[],'fp':0}\n",
    "    has_fp=False\n",
    "    has_tp=False\n",
    "    if rec in df_tp.index:\n",
    "        info = clip_info(rec,df_tp)\n",
    "        for i,spec in enumerate(info['species_id']):\n",
    "            t_min=info['t_min'][i]\n",
    "            t_max=info['t_max'][i]\n",
    "            overlap=(t_min < stop and t_min >= start) or (t_max >= start and t_max < stop)\n",
    "            if overlap == True:\n",
    "                has_tp=True\n",
    "                out['tp_spec'].append(spec)\n",
    "                out['tp']+=1\n",
    "    \n",
    "    if rec in df_fp.index:\n",
    "        info = clip_info(rec,df_fp)\n",
    "        for i,spec in enumerate(info['species_id']):\n",
    "            t_min=info['t_min'][i]\n",
    "            t_max=info['t_max'][i]\n",
    "            overlap=(t_min < stop and t_min >= start) or (t_max >= start and t_max < stop)\n",
    "            if overlap == True:\n",
    "                has_fp=True\n",
    "                out['fp_spec'].append(spec + 24)\n",
    "                out['fp']+=1   \n",
    "    return out\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# thoughts\n",
    "* turn each training clip into 1000 spectra (using large hop_length)\n",
    "* take 100 from (FP or TP) vs. NP for each training clip (if available)\n",
    "* Fit a moddel that predicts (FP or TP) from (NP) basically: does this clip contain something of interest?\n",
    "* Run same analysis pipeline on test data, but then predict usefulness of all segments in clip.\n",
    "* Train/test by taking top 256 clips from each\n",
    "* OR: dimensionality reduction of some other kind\n",
    "* OR: reduce size + create labels of all types of audio in clip for one-hot encoding\n",
    "* either way, reduce training and testing set size to maximally informative spectra\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "60000/200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn=df_tp.index[157]\n",
    "take_med=False\n",
    "clip_to_singer=False\n",
    "num_ds=1000\n",
    "src=TRAIN_AUDIO_ROOT.joinpath('0_raw').joinpath(fn).with_suffix(\".flac\")\n",
    "dest=CC_DATA_OUT.joinpath('spec_ds%d' % num_ds)\n",
    "if dest.exists()==False:\n",
    "    os.mkdir(dest)\n",
    "    \n",
    "for mode in modes:\n",
    "    if mode == 'TEST':\n",
    "        resume=0\n",
    "        use_df=df_test\n",
    "        src=TEST_AUDIO_ROOT \n",
    "        params.dest=dest.joinpath('test')\n",
    "    elif mode == 'TRAIN':\n",
    "        resume=0\n",
    "        use_df=df_train\n",
    "        src=TRAIN_AUDIO_ROOT\n",
    "        params.dest=dest.joinpath('train')\n",
    "    params.use_root=use_root\n",
    "       \n",
    "    if params.dest.exists() == False:\n",
    "        os.makedirs(params.dest)\n",
    "    for ii,fn in enumerate(use_df['recording_id'][resume:]):\n",
    "        pnfn=src.joinpath(fn).with_suffix(\".flac\")\n",
    "        _,fs=sf.read(pnfn)\n",
    "        \n",
    "        params.sr=fs\n",
    "        params.mode=mode\n",
    "\n",
    "        print('\\n%d of %d. Loading...' % (resume+ii, len(use_df['recording_id'])))        \n",
    "        params.fn=fn\n",
    "        y = load_audio(pnfn, params.sr)\n",
    "        params.hop_length=math.floor((fs*60)/num_ds)\n",
    "        print('\\tLoaded.')\n",
    "        params.rec_length=int(y.shape[0]/params.sr)\n",
    "\n",
    "        # Create spectrogram and relate to \n",
    "        melspec=compute_melspec(y,params)\n",
    "    \n",
    "        # Label each of these segments\n",
    "        spec=img.split('_')[1]\n",
    "        rec=img.split('_')[2]\n",
    "        rec_part=img.split('_')[3].split('.')[0]\n",
    "        clip_start=float(rec_part)*params.clip_dur\n",
    "        clip_stop= clip_start + params.clip_dur\n",
    "        info = clip_info(rec,df_tp)\n",
    "        for i,s in enumerate(info['species_id']):\n",
    "            if s == int(spec):\n",
    "                t_min=info['t_min'][i]\n",
    "                t_max=info['t_max'][i]\n",
    "                if (t_max > clip_start) and (t_min < clip_stop):\n",
    "                    #This call is within this clip.\n",
    "                    if ((t_max - clip_start) < params.min_dur) or ((clip_stop - t_min) < params.min_dur):\n",
    "                        #But only the very end or beginning of the call is in the clip\n",
    "                        shutil.move(str(fn),str(params.dest)) #Move to a separate folder\n",
    "                        print('%d) %s is %1.3f s == too short!' % (ii,img,np.min([(clip_stop - t_min),(t_max - clip_start)])))\n",
    "\n",
    "                        \n",
    "for i\n",
    "_,fs=sf.read(pnfn)\n",
    "singer=df_tp['species_id'][fn]\n",
    "params.sr=fs\n",
    "\n",
    "\n",
    "y = load_audio(fn, params.sr, TRAIN_AUDIO_ROOT.joinpath('0_raw'))\n",
    "params.hop_length=round(len(y)/1200)\n",
    "print(y.shape[0]/fs)\n",
    "start_t=0\n",
    "# end_t=round(60 * fs)\n",
    "end_t=round(0.2 * fs)\n",
    "if clip_to_singer == True:\n",
    "    if isinstance(singer,np.int64):\n",
    "        start_t=round(df_tp['t_min'][fn]*fs)\n",
    "        end_t= round(df_tp['t_max'][fn]*fs)\n",
    "    else:\n",
    "        start_t=round(df_tp['t_min'][fn][0]*fs)\n",
    "        end_t=round(df_tp['t_max'][fn][0]*fs)\n",
    "\n",
    "print((singer,fs,y.shape[0]/fs))\n",
    "keep = compute_melspec(y, params)\n",
    "y=y[start_t:end_t]\n",
    "melspec=compute_melspec(y,params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
