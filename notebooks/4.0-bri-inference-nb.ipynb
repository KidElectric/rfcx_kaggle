{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from fastai import learner\n",
    "from fastai.vision.all import *\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import librosa as lb\n",
    "import librosa.display\n",
    "import soundfile as sf\n",
    "import matplotlib.patches as patch\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "from pathlib import Path\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.io import wavfile\n",
    "from torch import cuda\n",
    "import shutil\n",
    "\n",
    "CC_ROOT=Path(\"D:\\\\KidElectric\\\\rfcx_kaggle\") #Cookiecutter datascience-style project\n",
    "CC_DATA_TEST=CC_ROOT.joinpath('data').joinpath('interim').joinpath('test')\n",
    "CC_MODEL_ROOT=CC_ROOT.joinpath('models').joinpath('fit')\n",
    "\n",
    "DATA_ROOT = CC_ROOT.joinpath('data')\n",
    "TRAIN_AUDIO_ROOT = DATA_ROOT.joinpath('raw').joinpath('train')#Update to point to cookiecutter data/raw/train\n",
    "TEST_AUDIO_ROOT = DATA_ROOT.joinpath('raw').joinpath('test')#Update to point to cookiecutter data/raw/test\n",
    "\n",
    "\n",
    "df_train = pd.DataFrame({\n",
    "    \"recording_id\": [path.stem for path in TRAIN_AUDIO_ROOT.glob(\"*.flac\")],\n",
    "})\n",
    "\n",
    "df_test = pd.DataFrame({\n",
    "    \"recording_id\": [path.stem for path in TEST_AUDIO_ROOT.glob(\"*.flac\")],\n",
    "})\n",
    "\n",
    "\n",
    "df_tp=pd.read_csv(CC_ROOT.joinpath('references').joinpath('train_tp.csv')).set_index('recording_id')\n",
    "\n",
    "df_fp=pd.read_csv(CC_ROOT.joinpath('references').joinpath('train_fp.csv')).set_index('recording_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load a model:\n",
    "def which_singer(x): return x.parts[-1].split('_')[1] #Need to define this function first\n",
    "# model_name='rn101_50ep_512_clip_full_aug2_noflip_FB_120320_mixup0p5.pkl'\n",
    "model_name='rn101_50ep_lr8p32e-10_434_clip_TP_FP_NP_aug2_noflip_120420_mixup0p5.pkl'\n",
    "learn=load_learner(CC_MODEL_ROOT.joinpath(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished\n"
     ]
    }
   ],
   "source": [
    "# Predict many images at once \n",
    "imgs=[png for png in CC_DATA_TEST.joinpath('clip_decomp').glob('*.png')]\n",
    "dl = learn.dls.test_dl(imgs, item_tfms=Resize(512,ResizeMethod.Squish),num_workers=0,bs=64)\n",
    "a,b=learn.get_preds(dl=dl) # or torch.softmax?\n",
    "prob_order= learn.dls.vocab\n",
    "recs=df_test['recording_id']\n",
    "df_prob=pd.DataFrame(index=df_test['recording_id'],columns=['s%d' % i for i in range(0,24,1)])\n",
    "m = nn.Softmax(dim=1)\n",
    "probs=m(a)\n",
    "for rec in recs:\n",
    "    temp=np.zeros((len(pngs),len(prob_order)))\n",
    "    n=0\n",
    "    for i,img in enumerate(imgs):\n",
    "        if rec == img.parts[-1].split('_')[0]:\n",
    "            temp[n,:]=probs[i,:]\n",
    "            n += 1\n",
    "    mp=np.mean(temp,axis=0) #Or should it be mean? -- doesn't seem to matter!\n",
    "    for i,spec in enumerate(prob_order):\n",
    "        if int(spec) < 24:\n",
    "            df_prob['s%s' % spec][rec]=float(mp[i])\n",
    "df_prob.to_csv(CC_MODEL_ROOT.parent.joinpath('predictions').joinpath('%s-sum.csv' % model_name[0:-4]))\n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model D:\\KidElectric\\rfcx_kaggle\\data\\processed\\resamp_33\\models\\rn18_30ep_512_resamp33_TP_aug1_noflip_0.pkl\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\KidElectric\\\\rfcx_kaggle\\\\data\\\\processed\\\\resamp_33\\\\models\\\\rn18_30ep_512_resamp33_TP_aug1_noflip_0.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-e09f3c577d79>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mmpath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoinpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'models'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loading model %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mmpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoinpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mlearn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mload_learner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoinpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[0mdl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_dl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem_tfms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mResize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mResizeMethod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSquish\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\tPredicting...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\fastai2\\lib\\site-packages\\fastai\\learner.py\u001b[0m in \u001b[0;36mload_learner\u001b[1;34m(fname, cpu)\u001b[0m\n\u001b[0;32m    549\u001b[0m     \u001b[1;34m\"Load a `Learner` object in `fname`, optionally putting it on the `cpu`\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    550\u001b[0m     \u001b[0mdistrib_barrier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 551\u001b[1;33m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'cpu'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcpu\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    552\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'to_fp32'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_fp32\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcpu\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\fastai2\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    579\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'encoding'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 581\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    582\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m             \u001b[1;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\fastai2\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 230\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    231\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'w'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\fastai2\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\KidElectric\\\\rfcx_kaggle\\\\data\\\\processed\\\\resamp_33\\\\models\\\\rn18_30ep_512_resamp33_TP_aug1_noflip_0.pkl'"
     ]
    }
   ],
   "source": [
    "# Predict many images from many models:\n",
    "rs = 33\n",
    "nmodels=20\n",
    "path =CC_ROOT.joinpath('data').joinpath('processed').joinpath('resamp_%d' % rs)\n",
    "imgs=[png for png in CC_DATA_TEST.joinpath('clip_decomp').glob('*.png')]\n",
    "im_size=512 # 224\n",
    "nspec=24\n",
    "def which_singer(x): return x.parts[-1].split('_')[1] #Need to define this function first\n",
    "for ii in range(nmodels):\n",
    "#     model_name='rn50_50ep_%d_resamp%d_TP_FP_NP_aug2_noflip_%d.pkl' % (im_size,rs,ii) #Each of these models was pretty bad on their own (~0.65 error rate)\n",
    "#     model_name='rn101_50ep_%d_resamp%d_TP_FP_NP_aug2_noflip_mixup0p5_%d.pkl' % (im_size,rs,ii)\n",
    "    model_name='rn18_30ep_%d_resamp%d_TP_aug1_noflip_%d.pkl' %(im_size,rs,ii)\n",
    "    mpath=path.joinpath('models')\n",
    "    print('Loading model %s' % mpath.joinpath(model_name))\n",
    "    learn=load_learner(mpath.joinpath(model_name))\n",
    "    dl = learn.dls.test_dl(imgs, item_tfms=Resize(im_size,ResizeMethod.Squish),num_workers=0,bs=64)\n",
    "    print('\\tPredicting...')\n",
    "    a,b=learn.get_preds(dl=dl) # or torch.softmax?\n",
    "    prob_order= learn.dls.vocab\n",
    "    recs=df_test['recording_id']\n",
    "    df_prob=pd.DataFrame(index=df_test['recording_id'],columns=['s%d' % i for i in range(0,24,1)])\n",
    "    m = nn.Softmax(dim=1)\n",
    "    probs=m(a)\n",
    "    for rec in recs:\n",
    "        temp=np.zeros((len(imgs),len(prob_order)))\n",
    "        n=0\n",
    "        for i,img in enumerate(imgs):\n",
    "            if rec == img.parts[-1].split('_')[0]:\n",
    "                temp[n,:]=probs[i,:]\n",
    "                n += 1\n",
    "        mp=np.mean(temp,axis=0) #Or should it be mean? -- doesn't seem to matter!\n",
    "        for i,spec in enumerate(prob_order):\n",
    "            if int(spec) < nspec:\n",
    "                df_prob['s%s' % spec][rec]=float(mp[i])\n",
    "    print('\\tSaving')\n",
    "    df_prob.to_csv(mpath.joinpath('%s.csv' % model_name[0:-4]))\n",
    "    \n",
    "#Load in multiple .csv and take the mean:\n",
    "csv_fns=mpath.glob( model_name[0:-7] + '*.csv')\n",
    "df_load={}\n",
    "for i,fn in enumerate(csv_fns):\n",
    "    df_load[i]= pd.read_csv(fn)\n",
    "b=df_load[0]\n",
    "for col in df_load[0].columns:\n",
    "    if col != 'recording_id':\n",
    "        for k in df_load.keys():\n",
    "            b[col]=b[col] + df_load[k][col]\n",
    "        b[col]= b[col]/nspec\n",
    "b.head()\n",
    "b.to_csv(mpath.joinpath('%s_%d_averaged.csv' % (model_name[0:-4],len(df_load))), index=False)\n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished\n"
     ]
    }
   ],
   "source": [
    "#Load in multiple .csv and take the mean:\n",
    "csv_fns=mpath.glob( model_name[0:-7] + '*.csv')\n",
    "df_load={}\n",
    "for i,fn in enumerate(csv_fns):\n",
    "    df_load[i]= pd.read_csv(fn)\n",
    "b=df_load[0]\n",
    "for col in df_load[0].columns:\n",
    "    if col != 'recording_id':\n",
    "        for k in df_load.keys():\n",
    "            b[col]=b[col] + df_load[k][col]\n",
    "        b[col]= b[col]/nspec\n",
    "b.head()\n",
    "b.to_csv(mpath.joinpath('%s_%d_averaged.csv' % (model_name[0:-4],len(df_load))), index=False)\n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('D:/KidElectric/rfcx_kaggle/data/processed/resamp_15/models')"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
